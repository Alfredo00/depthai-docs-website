---
layout: default
title: DepthAI RPi HAT
toc_title: RPi HAT
screenshot: /images/products/depthai-edition-rpi-hat.jpg
description: DepthAI HAT for Raspberry Pi (3, 3B+, and 4). Add your choice of cameras.
order: 2
---

# {{page.title}}

![{{page.toc_title}}]({{page.screenshot}})

The Raspberry Pi HAT Edition allows using the Raspberry Pi you already have and passes through the Pi GPIO so that these are still accessible and usable in your system(s). Its modular cameras allow mounting to your platform where you need them, up to six inches away from the HAT.

* Mounts to Raspberry Pi as a HAT for easy integration
* All Raspberry Pi GPIO still accessible through pass-through header
* Flexible Camera Mounting with 6" flexible flat cables
* Includes three FFC Camera ports

## Board Layout

![RPi HAT Labeled](/images/products/labeled/1094.jpg)

<table class="table table-sm">
<tbody>
<tr>
<td><strong>A.</strong> Left Camera Port</td><td><strong>E.</strong> Pass-through 40-Pin Raspberry Pi Header</td></tr>
<tr>
<td><strong>B.</strong> Right Camera Port</td><td><strong>F.</strong> Color Camera Port</td></tr>
<tr>
<td><strong>C.</strong> USB 3.0 Type-C</td><td><strong>G.</strong> 40-pin Raspberry Pi Header</td></tr>
<tr>
<td><strong>D.</strong> DepthAI Module</td><td></td></tr>
</tbody>
</table>


{: #in_box}
## What's in the box?

* {{page.title}} Carrier Board
* Pre-flashed µSD card loaded with Raspbian and DepthAI
* USB3C cable (6 in.)
* Power Supply

## Setup

Follow the steps below to setup your DepthAI device.

<h3 class="step js-toc-ignore"><span>1</span> Connect your host to the DepthAI USB carrier board.</h3>

<h3 class="step js-toc-ignore"><span>2</span> Connect the DepthAI USB power supply (included).</h3>

<h3 class="step js-toc-ignore"><span>3</span> Insert the pre-flashed µSD card into your RPi host.</h3>

The µSD card is pre-configured with Raspbian and DepthAI.

<h3 class="step js-toc-ignore"><span>4</span> Install the Python DepthAI API.</h3>

[See our instructions](/api#install).

<h3 class="step js-toc-ignore"><span>5</span> Calibrate Stereo Cameras.</h3>

Have the stereo camera pair? Use the DepthAI [calibration script](/products/stereo_camera_pair/#calibration).

<h3 class="step js-toc-ignore"><span>6</span> Run the DepthAI Python test script.</h3>

We'll execute a DepthAI example Python script to ensure your setup is configured correctly. Follow these steps to test DepthAI:

1. Start a terminal session.
2. Access your local copy of of the `depthai-python-extras` from step 4.
    ```
    cd [depthai-python-extras repo from step 4]
    ```
3. Run `python3 examples/test.py`.<br/>
    The script launches a window, starts the cameras, and displays a video stream annotated with object localization metadata:

    {: style="max-width:50%"}
    ![object localization demo](/images/object_localization.png)

    In the screenshot above, DepthAI identified a tv monitor (1.286 m from the camera) and a chair (3.711 m from the camera). See [the list of object labels](https://github.com/luxonis/depthai-python-extras/blob/master/resources/nn/object_detection_4shave/labels_for_mobilenet_ssd.txt) on GitHub.
